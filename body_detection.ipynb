{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import logging\n",
    "from itertools import repeat\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPool2D, UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачать веса - https://pjreddie.com/media/files/yolov3.weights \n",
    "\n",
    "Источник кода - http://datahacker.rs/tensorflow2-0-yolov3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_iou_threshold = 0.6 # Intersection Over Union (iou) threshold.\n",
    "yolo_score_threshold = 0.6 # Score threshold.\n",
    "\n",
    "weightyolov3 = 'yolov3.weights' # Путь до файла с весами.\n",
    "size = 416 # Размер изображения. \n",
    "num_classes = 80 # Количество классов в модели.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_darknet_weights(model, weights_file):\n",
    "    wf = open(weights_file, 'rb')\n",
    "    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "    layers = [\n",
    "        'yolo_darknet',\n",
    "        'yolo_conv_0',\n",
    "        'yolo_output_0',\n",
    "        'yolo_conv_1',\n",
    "        'yolo_output_1',\n",
    "        'yolo_conv_2',\n",
    "        'yolo_output_2'\n",
    "        ]\n",
    "\n",
    "    for layer_name in layers:\n",
    "        sub_model = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(sub_model.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            batch_norm = None\n",
    "            if i + 1 < len(sub_model.layers) and \\\n",
    "                sub_model.layers[i + 1].name.startswith('batch_norm'):\n",
    "                    batch_norm = sub_model.layers[i + 1]\n",
    "\n",
    "            logging.info(\"{}/{} {}\".format(\n",
    "                sub_model.name, layer.name, 'bn' if batch_norm else 'bias'))\n",
    "            \n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.input_shape[-1]\n",
    "\n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                bn_weights = np.fromfile(wf, dtype=np.float32, count=4*filters)\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n",
    "\n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n",
    "\n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "\n",
    "    assert len(wf.read()) == 0, 'failed to read weights'\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
    "    def call(self, x, training=False):\n",
    "        if training is None: training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n",
    "\n",
    "# Определяем 3 anchor box'а для каждой ячейки.   \n",
    "yolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),\n",
    "                        (59, 119), (116, 90), (156, 198), (373, 326)], np.float32) / 416\n",
    "yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
    "        padding = 'valid'\n",
    "    x = Conv2D(filters=filters, kernel_size=size,\n",
    "              strides=strides, padding=padding,\n",
    "              use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(alpha=0.1)(x)\n",
    "    return x\n",
    "\n",
    "def DarknetResidual(x, filters):\n",
    "    previous = x\n",
    "    x = DarknetConv(x, filters // 2, 1)\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([previous , x])\n",
    "    return x\n",
    "\n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters, 3, strides=2)\n",
    "    for _ in repeat(None, blocks):\n",
    "        x = DarknetResidual(x, filters)       \n",
    "    return x\n",
    "\n",
    "def Darknet(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)\n",
    "    x = x_36 = DarknetBlock(x, 256, 8)\n",
    "    x = x_61 = DarknetBlock(x, 512, 8)\n",
    "    x = DarknetBlock(x, 1024, 4)\n",
    "    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)\n",
    "  \n",
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv\n",
    "  \n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                        anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_output\n",
    "\n",
    "def yolo_boxes(pred, anchors, classes):\n",
    "    grid_size = tf.shape(pred)[1]\n",
    "    box_xy, box_wh, score, class_probs = tf.split(pred, (2, 2, 1, classes), axis=-1)\n",
    "\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    score = tf.sigmoid(score)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "\n",
    "    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "\n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) /  tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "\n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "    \n",
    "    return bbox, score, class_probs, pred_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonMaximumSuppression(outputs, anchors, masks, classes):\n",
    "    boxes, conf, out_type = [], [], []\n",
    "\n",
    "    for output in outputs:\n",
    "        boxes.append(tf.reshape(output[0], (tf.shape(output[0])[0], -1, tf.shape(output[0])[-1])))\n",
    "        conf.append(tf.reshape(output[1], (tf.shape(output[1])[0], -1, tf.shape(output[1])[-1])))\n",
    "        out_type.append(tf.reshape(output[2], (tf.shape(output[2])[0], -1, tf.shape(output[2])[-1])))\n",
    "\n",
    "    bbox = tf.concat(boxes, axis=1)\n",
    "    confidence = tf.concat(conf, axis=1)\n",
    "    class_probs = tf.concat(out_type, axis=1)\n",
    "\n",
    "    scores = confidence * class_probs\n",
    "  \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),\n",
    "        max_output_size_per_class=100,\n",
    "        max_total_size=100,\n",
    "        iou_threshold=yolo_iou_threshold,\n",
    "        score_threshold=yolo_score_threshold)\n",
    "  \n",
    "    return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloV3(size=None, channels=3, anchors=yolo_anchors,\n",
    "            masks=yolo_anchor_masks, classes=80, training=False):\n",
    "    x = inputs = Input([size, size, channels])\n",
    "\n",
    "    x_36, x_61, x = Darknet(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConv(512, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "\n",
    "    x = YoloConv(256, name='yolo_conv_1')((x, x_61))\n",
    "    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    x = YoloConv(128, name='yolo_conv_2')((x, x_36))\n",
    "    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1, output_2), name='yolov3')\n",
    "\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                  name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                  name='yolo_boxes_1')(output_1)\n",
    "    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),\n",
    "                  name='yolo_boxes_2')(output_2)\n",
    "\n",
    "    outputs = Lambda(lambda x: nonMaximumSuppression(x, anchors, masks, classes),\n",
    "                  name='nonMaximumSuppression')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))\n",
    "\n",
    "    return Model(inputs, outputs, name='yolov3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YoloV3(classes=num_classes)\n",
    "\n",
    "load_darknet_weights(yolo, weightyolov3)\n",
    "\n",
    "\n",
    "class_names =  [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
    "    \"banana\",\"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\",\n",
    "    \"cake\",\"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \n",
    "    \"mouse\",\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n",
    "    \"refrigerator\",\"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outputs(img, outputs, class_names, white_list=None):\n",
    "    boxes, score, classes, nums = outputs\n",
    "    boxes, score, classes, nums = boxes[0], score[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        if class_names[int(classes[i])] not in white_list:\n",
    "            continue\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)\n",
    "        img = cv2.putText(img, '{} {:.4f}'.format(\n",
    "            class_names[int(classes[i])], score[i]),\n",
    "            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('humans_1.mp4')\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "# the output will be written to output.avi\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    image = tf.expand_dims(frame, 0)\n",
    "    image = tf.image.resize(image, (size, size)) / 255\n",
    "    \n",
    "    boxes, scores, classes, nums = yolo(image)\n",
    "    frame = draw_outputs(frame, (boxes, scores, classes, nums), class_names, ['person'])\n",
    "    \n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
